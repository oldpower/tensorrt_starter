import numpy as np
import cv2
import os
import torchvision.transforms as transforms
import torch
import torch.nn as nn
from torchvision.models import vit_b_32, ViT_B_32_Weights
from PIL import Image
import time

current_dir = os.path.dirname(os.path.abspath(__file__))

def initVit():
    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å’Œæƒé‡
    weights = ViT_B_32_Weights.DEFAULT
    vit_model = vit_b_32(weights=weights)
    vit_model.eval()
    # å®šä¹‰ViTé¢„å¤„ç†å˜æ¢
    vit_transform = transforms.Compose([
        transforms.Resize((224, 224)),  # ç¡®ä¿å°ºå¯¸æ­£ç¡®
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])
    return vit_model,vit_transform

def vitDemo():
    # LL_dir = os.path.join(current_dir,'assets/StirringLL_cut')
    # LL_Image_List = sorted(os.listdir(LL_dir))

    LS_dir = os.path.join(current_dir,'assets/StirringSL_cut')
    LS_Image_List = sorted(os.listdir(LS_dir))

    vit_model,vit_transform = initVit()
    
    # ROI å‚æ•°
    # x, y, w, h = 700, 750, 100, 550
    x, y, w, h = 740, 1200, 70, 100
    rectangle_current = None
    rectangle_hisory = None
    process = True
    patches = []  # å­˜æ”¾æ¯ä¸ª 32x32 çš„ patch
    for image_name in LS_Image_List:
        image_path = os.path.join(LS_dir,image_name)

        frame = cv2.imread(image_path)

        # cv2.rectangle(img       = img,
        #               rec       = (x, y, w, h),
        #               color     = (0,255,0),
        #               thickness = 2)
        if rectangle_hisory is None:
            rectangle_hisory = frame[y:y+h,x:x+w]
            roi = frame[y:y+32, x:x+32]  # æå– 32x32 åŒºåŸŸ
            continue

        rectangle_current = frame[y:y+h,x:x+w]
        roi = frame[y:y+32, x:x+32]  # æå– 32x32 åŒºåŸŸ
        patches.append(roi)
        if len(patches) == 7*7:
            patches = np.array(patches)  # å½¢çŠ¶å˜ä¸º (49, 32, 32, 3)
            grid = patches.reshape(7, 7, 32, 32, 3)
            # äº¤æ¢è½´ï¼Œå‡†å¤‡æ‹¼æ¥: (7, 32, 7, 32, 3)
            grid = np.transpose(grid, (0, 2, 1, 3, 4))
            # åˆå¹¶ç©ºé—´ç»´åº¦
            # å…ˆåœ¨è¡Œæ–¹å‘æ‹¼æ¥ï¼ˆæ¯è¡Œ7ä¸ª patch æ¨ªå‘æ‹¼ï¼‰
            # rows = [np.concatenate(grid[i], axis=1) for i in range(7)]  # æ¯è¡Œ: (32, 224, 3)
            rows = [np.concatenate([grid[i, :, j] for j in range(7)], axis=1) for i in range(7)]
            print(len(rows),rows[0].shape)
            print(grid.shape)
            print(grid[0, :, 0].shape)
            # å†æŠŠ7è¡Œçºµå‘æ‹¼æ¥
            concatenated = np.concatenate(rows, axis=0)  # æœ€ç»ˆ: (224, 224, 3)
            print(concatenated.shape)

            
            cv2.imwrite('./assets/vitconcatenated.jpg',concatenated) 
            # å‡†å¤‡è¾“å…¥ViTæ¨¡å‹
            # 1. å°†BGRè½¬æ¢ä¸ºRGB
            concatenated_rgb = cv2.cvtColor(concatenated, cv2.COLOR_BGR2RGB)
            # 2. è½¬æ¢ä¸ºPILå›¾åƒ
            pil_image = Image.fromarray(concatenated_rgb)
            # 3. åº”ç”¨ViTé¢„å¤„ç†
            input_tensor = vit_transform(pil_image)
            # 4. æ·»åŠ batchç»´åº¦ [1, 3, 224, 224]
            input_batch = input_tensor.unsqueeze(0)
            print(f"ViTè¾“å…¥å¼ é‡å½¢çŠ¶: {input_batch.shape}")
            # ç°åœ¨å¯ä»¥å°† input_batch è¾“å…¥åˆ°ViTæ¨¡å‹ä¸­
            with torch.no_grad():
                output = vit_model(input_batch)
                print(output.shape)
                print(output[0][:10])

            
            patches = []
            break


        if process:
            pass

def createDataset():
    import random
    from pathlib import Path
    current_dir = os.path.dirname(os.path.abspath(__file__))
    random.seed(10)
    
    # å®šä¹‰æºç›®å½•å’Œç›®æ ‡ç›®å½•
    source_A = os.path.join(current_dir, 'assets', 'StirringLL')
    source_B = os.path.join(current_dir, 'assets', 'StirringSL')
    target_dataset = os.path.join(current_dir, 'assets', 'dataset', 'vitdataset')
    
    # ç±»åˆ«åç§°ï¼ˆç”¨äºç›®æ ‡æ–‡ä»¶å¤¹å‘½åï¼‰
    class_A_name = 'StirringLL'
    class_B_name = 'StirringSL'
    
    # åˆ›å»ºç›®æ ‡ç›®å½•ç»“æ„
    train_A = os.path.join(target_dataset, 'train', class_A_name)
    train_B = os.path.join(target_dataset, 'train', class_B_name)
    val_A = os.path.join(target_dataset, 'val', class_A_name)
    val_B = os.path.join(target_dataset, 'val', class_B_name)
    
    for dir_path in [train_A, train_B, val_A, val_B]:
        os.makedirs(dir_path, exist_ok=True)
    
    def process_class(source_dir, class_name):
        if not os.path.exists(source_dir):
            print(f"æºç›®å½•ä¸å­˜åœ¨: {source_dir}")
            return
        
        # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶ï¼ˆå¯æ ¹æ®éœ€è¦æ‰©å±•åç¼€ï¼‰
        extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}
        all_files = [
            f for f in os.listdir(source_dir)
            if os.path.isfile(os.path.join(source_dir, f)) and
            Path(f).suffix.lower() in extensions
        ]
        
        if not all_files:
            print(f"åœ¨ {source_dir} ä¸­æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
            return
        
        # éšæœºæ‰“ä¹±
        random.shuffle(all_files)
        
        # æŒ‰ 8:2 åˆ’åˆ†
        split_idx = int(0.8 * len(all_files))
        train_files = all_files[:split_idx]
        val_files = all_files[split_idx:]
        
        # ä¸ºè®­ç»ƒé›†åˆ›å»ºè½¯é“¾æ¥
        for fname in train_files:
            src = os.path.join(source_dir, fname)
            dst = os.path.join(train_A if class_name == 'StirringLL' else train_B, fname)
            create_symlink(src, dst)
        
        # ä¸ºéªŒè¯é›†åˆ›å»ºè½¯é“¾æ¥
        for fname in val_files:
            src = os.path.join(source_dir, fname)
            dst = os.path.join(val_A if class_name == 'StirringLL' else val_B, fname)
            create_symlink(src, dst)
        
        print(f"{class_name}: {len(train_files)} è®­ç»ƒ, {len(val_files)} éªŒè¯")
    
    def create_symlink(src, dst):
        """åˆ›å»ºè½¯é“¾æ¥ï¼Œè‹¥ç›®æ ‡å·²å­˜åœ¨åˆ™åˆ é™¤"""
        if os.path.exists(dst) or os.path.islink(dst):
            os.remove(dst)
        try:
            os.symlink(src, dst)
            # print(f"é“¾æ¥: {dst} -> {src}")
        except Exception as e:
            print(f"åˆ›å»ºè½¯é“¾æ¥å¤±è´¥ {dst} -> {src}: {e}")
            # å¤‡ç”¨ï¼šå¦‚æœè½¯é“¾æ¥å¤±è´¥ï¼ˆå¦‚Windowsæƒé™é—®é¢˜ï¼‰ï¼Œå¯æ”¹ä¸ºå¤åˆ¶
            # shutil.copy2(src, dst)
    
    # å¤„ç†ä¸¤ä¸ªç±»åˆ«
    process_class(source_A, class_A_name)
    process_class(source_B, class_B_name)

    print("æ•°æ®é›†åˆ’åˆ†ä¸è½¯é“¾æ¥åˆ›å»ºå®Œæˆï¼")
    print(f"æ•°æ®é›†è·¯å¾„: {target_dataset}")

def trainVit():
    from torchvision import datasets
    import torch.optim as optim
    from torch.optim.lr_scheduler import StepLR

    vit_model,vit_transform = initVit()

    # ä½¿ç”¨ä¸é¢„è®­ç»ƒç›¸åŒçš„ transformï¼ˆéå¸¸é‡è¦ï¼ï¼‰
    train_dataset = datasets.ImageFolder(root='./assets/dataset/vitdataset/train', transform=vit_transform)
    val_dataset = datasets.ImageFolder(root='./assets/dataset/vitdataset/val', transform=vit_transform)
    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)

    num_class  = 2
    num_epochs = 2

    vit_model.heads.head = torch.nn.Linear(vit_model.heads.head.in_features, num_class)
    # vit_model.heads = torch.nn.Linear(vit_model.heads.head.in_features, num_class)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    vit_model.to(device)

    criterion  = nn.CrossEntropyLoss()
    optimizer  = optim.Adam(vit_model.heads.parameters(), lr=1e-3)  # åªè®­ç»ƒåˆ†ç±»å¤´ï¼ˆå¿«é€Ÿï¼‰
    # æˆ–è€…è®­ç»ƒæ•´ä¸ªæ¨¡å‹ï¼ˆæ›´æ…¢ä½†å¯èƒ½æ›´å¥½ï¼‰ï¼š
    # optimizer = optim.Adam(vit_model.parameters(), lr=1e-5)
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler  = StepLR(optimizer, step_size=7, gamma=0.1)
    
    print("ğŸš€ start train.")
    vit_model.train()
    for epoch in range(num_epochs):
        running_loss = 0.0
        correct = 0
        total = 0

        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = vit_model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

        print(f"Epoch [{epoch+1}/{num_epochs}], "
              f"Loss: {running_loss/len(train_loader):.4f}, "
              f"Acc: {100.*correct/total:.2f}%")

        scheduler.step()

        # éªŒè¯
        vit_model.eval()
        val_correct = 0
        val_total = 0
        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = vit_model(inputs)
                _, predicted = outputs.max(1)
                val_total += labels.size(0)
                val_correct += predicted.eq(labels).sum().item()
        print(f"Val Acc: {100.*val_correct/val_total:.2f}%")
        vit_model.train()

        torch.save(vit_model.state_dict(), './models/vit_b_32_2class.pth')
        print('savemodel ./models/vit_b_32_2class.pth')
    print("Training finished!")

def predictVit():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    num_class = 2

    vit_model,vit_transform = initVit()
    # vit_model.heads.head = nn.Linear(768, 2)  # é‡æ–°å®šä¹‰
    vit_model.heads.head = torch.nn.Linear(vit_model.heads.head.in_features, num_class)
    vit_model.load_state_dict(torch.load('./models/vit_b_32_2class.pth'))
    vit_model.to(device)
    vit_model.eval()
    
    pil_image = Image.open(os.path.join(current_dir,'./assets/StirringLL/20250814-StirringLiquidLiquid_frame_0000.png'))
    pil_image = Image.open(os.path.join(current_dir,'./assets/StirringSL/20250814-StirringSolidLiquid_frame_0000.png'))
    # 3. åº”ç”¨ViTé¢„å¤„ç†
    input_tensor = vit_transform(pil_image)
    input_batch = input_tensor.unsqueeze(0).to(device)
    # input_batch = torch.cat([input_batch,input_batch],dim=0)
    with torch.no_grad():
        for _ in range(5):
            starttime = time.time()
            output = vit_model(input_batch)
            print(f"â°torchæ¨ç†è€—æ—¶: {time.time() - starttime:.4f}")
            probabilities = torch.nn.functional.softmax(output, dim=1)
            
            print("åŸå§‹è¾“å‡ºï¼š", output)
            print("æ¦‚ç‡åˆ†å¸ƒï¼š", probabilities)
            # è·å–ç±»åˆ«åŠå…¶å¯¹åº”çš„æ¦‚ç‡
            prob_values, predicted_classes = torch.max(probabilities, 1)
            print(f"é¢„æµ‹ç±»åˆ«: {predicted_classes.item()}, æ¦‚ç‡: {prob_values.item()}")

def export_norm_onnx():
    import onnx
    import onnxsim

    file    = os.path.join(current_dir,'models/vit_b_32_2class.onnx')
    input   = torch.rand(1, 3, 224, 224, device='cuda')

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    # device = torch.device("cpu")
    num_class = 2
    vit_model,_ = initVit()
    # vit_model.heads.head = nn.Linear(768, 2)  # é‡æ–°å®šä¹‰
    vit_model.heads.head = torch.nn.Linear(vit_model.heads.head.in_features, num_class)
    vit_model.load_state_dict(torch.load('models/vit_b_32_2class.pth'))
    vit_model.to(device)
    # vit_model = torch.jit.script(vit_model,input) 
    # vit_model = torch.jit.trace(vit_model,input) 
    torch.onnx.export(
        model         = vit_model, 
        args          = (input,),
        f             = file,
        input_names   = ["input0"],
        output_names  = ["output0"],
        dynamic_axes  = {"input0" :{0:"batch"},
                         "output0":{0:"batch"}},
        opset_version = 15)
    print("Finished normal onnx export")

    model_onnx = onnx.load(file)

    # æ£€æŸ¥å¯¼å…¥çš„onnx model
    onnx.checker.check_model(model_onnx)

    # ä½¿ç”¨onnx-simplifieræ¥è¿›è¡Œonnxçš„ç®€åŒ–ã€‚
    print(f"Simplifying with onnx-simplifier {onnxsim.__version__}...")
    model_onnx, check = onnxsim.simplify(model_onnx)
    assert check, "assert check failed"
    onnx.save(model_onnx, file)

def inference_onnx():
    import onnxruntime as ort
    import onnx

    # åŠ è½½ ONNX æ¨¡å‹ï¼ˆå¯é€‰ï¼Œç”¨äºæŸ¥çœ‹ä¿¡æ¯ï¼‰
    model_onnx = onnx.load('./models/vit_b_32_2class.onnx')
    print("æ¨¡å‹è¾“å…¥å:", model_onnx.graph.input[0].name)
    print("æ¨¡å‹è¾“å‡ºå:", model_onnx.graph.output[0].name)

    # åˆ›å»º ONNX Runtime æ¨ç†ä¼šè¯
    session = ort.InferenceSession('./models/vit_b_32_2class.onnx', providers=['CPUExecutionProvider'])
    # å¦‚æœæœ‰ GPUï¼Œå¯ä»¥ä½¿ç”¨:
    # session = ort.InferenceSession('./models/vit_b_32_2class.onnx', providers=['CUDAExecutionProvider'])

    # è·å–è¾“å…¥ä¿¡æ¯
    input_name = session.get_inputs()[0].name
    print("è¾“å…¥èŠ‚ç‚¹å:", input_name)

    # åŠ è½½å¹¶é¢„å¤„ç†å›¾ç‰‡
    # image_path = './assets/StirringLL/20250814-StirringLiquidLiquid_frame_0000.png'
    # pil_image = Image.open(image_path).convert('RGB')
    pil_image = Image.open(os.path.join(current_dir,'./assets/StirringLL/20250814-StirringLiquidLiquid_frame_0000.png'))
    pil_image = Image.open(os.path.join(current_dir,'./assets/StirringSL/20250814-StirringSolidLiquid_frame_0000.png'))

    # æ³¨æ„ï¼šONNX æ¨¡å‹çš„è¾“å…¥æ˜¯ç»è¿‡é¢„å¤„ç†çš„å¼ é‡ï¼Œå¿…é¡»å’Œè®­ç»ƒæ—¶ä¸€è‡´ï¼
    from torchvision import transforms
    transform = transforms.Compose([
        transforms.Resize((224,224)),  # ViT-B/32 ä½¿ç”¨ 224x224
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])

    input_tensor = transform(pil_image).unsqueeze(0)  # æ·»åŠ  batch ç»´åº¦
    # input_tensor = torch.cat([input_tensor, input_tensor], dim=0)
    input_numpy = input_tensor.numpy()  # è½¬ä¸º numpy array
    print(input_numpy.shape)
   
    for _ in range(5):
        # æ¨ç†
        starttime = time.time()
        outputs = session.run(None, {input_name: input_numpy})  # None è¡¨ç¤ºè¿”å›æ‰€æœ‰è¾“å‡º
        print(f"â°onnxæ¨ç†è€—æ—¶: {time.time() - starttime:.4f}")

        # è·å–è¾“å‡º
        logits = outputs[0]  # shape: [1, num_classes]
        # print("åŸå§‹è¾“å‡º:", logits)
        # è½¬ä¸ºæ¦‚ç‡ï¼ˆSoftmaxï¼‰
        probabilities = torch.softmax(torch.from_numpy(logits), dim=1).numpy()[0]
        # print("æ¦‚ç‡åˆ†å¸ƒ:", probabilities)
        # è·å–é¢„æµ‹ç±»åˆ«
        predicted_class = probabilities.argmax()
        # print(f"é¢„æµ‹ç±»åˆ«: {predicted_class}, ç½®ä¿¡åº¦: {probabilities[predicted_class]:.4f}")

def inference_trt():
    from z_trt import inference_TRTInfer
    inference_TRTInfer()
if __name__ == "__main__":
    # vitDemo()
    # createDataset()
    # trainVit() 
    # predictVit()
    # export_norm_onnx()
    inference_onnx()
    inference_trt()




    
